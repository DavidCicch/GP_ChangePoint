{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n",
      "\n",
      "****** PyMBAR will use 64-bit JAX! *******\n",
      "* JAX is currently set to 32-bit bitsize *\n",
      "* which is its default.                  *\n",
      "*                                        *\n",
      "* PyMBAR requires 64-bit mode and WILL   *\n",
      "* enable JAX's 64-bit mode when called.  *\n",
      "*                                        *\n",
      "* This MAY cause problems with other     *\n",
      "* Uses of JAX in the same code.          *\n",
      "******************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/davcic/CP_Testing')\n",
    "sys.path.append('/home/davcic/CP_Testing/HDPHMM')\n",
    "\n",
    "import hdphmm\n",
    "from hdphmm import generate_timeseries as gent\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import generate_timeseries as gent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 23:13:10.688508: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "print(f'Selected CPU')\n",
    "\n",
    "import jax\n",
    "import jax.random as jrnd\n",
    "import jax.numpy as jnp\n",
    "import distrax as dx\n",
    "import jaxkern as jk\n",
    "\n",
    "# from jax.config import config\n",
    "# config.update(\"jax_enable_x64\", True)  # crucial for Gaussian processes\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "\n",
    "sys.path.append('/home/davcic/CP_Testing')\n",
    "\n",
    "from New_kernel_1 import Discontinuous_multiple\n",
    "from New_kernel_1 import Discontinuous_multiple_params\n",
    "from New_kernel_1 import Discontinuous_multiple_params_hyper\n",
    "from Poisson_Process_added import Poisson_Process_hyper\n",
    "from Uniform_modified import Uniform_mod\n",
    "from Normal_modified import LogNormal_mod\n",
    "import gc\n",
    "\n",
    "sys.path.append('/home/davcic/CP_Testing/Classes')\n",
    "\n",
    "from GP_CP import GP_CP_Marginal, GP_CP_Latent\n",
    "\n",
    "name = 'Toy_dataset_RBF_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 3\n",
    "\n",
    "GP_marginal = []\n",
    "GP_latent = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    GP_marginal.append(jnp.load(name + f'/GP_Marginal/GP_marginal_trained_{i}.npy', allow_pickle = True)[()])\n",
    "    GP_latent.append(jnp.load(name + f'/GP_Latent/GP_latent_trained_{i}.npy', allow_pickle = True)[()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = jnp.load(name + f'/ground_truth.npy', allow_pickle = True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.9524, dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GP_marginal[0].jaccard_metric(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrnd.PRNGKey(1234)\n",
    "number_metric = jnp.zeros((2, 3))\n",
    "location_metric = jnp.zeros((2, 3))\n",
    "likelihood_metric = jnp.zeros((2, 3))\n",
    "jaccard_metric = jnp.zeros((2, 3))\n",
    "\n",
    "for i in range(num_runs):\n",
    "    jaccard_metric = jaccard_metric.at[0, i].set(GP_marginal[i].jaccard_metric(ground_truth))\n",
    "    number_metric = number_metric.at[0, i].set(GP_marginal[i].number_metric(ground_truth))\n",
    "    location_metric = location_metric.at[0, i].set(GP_marginal[i].location_metric(ground_truth))\n",
    "    likelihood_metric = likelihood_metric.at[0, i].set(GP_marginal[i].likelihood_metric(key))\n",
    "    number_metric = number_metric.at[1, i].set(GP_latent[i].number_metric(ground_truth))\n",
    "    location_metric = location_metric.at[1, i].set(GP_latent[i].location_metric(ground_truth))\n",
    "    likelihood_metric = likelihood_metric.at[1, i].set(GP_latent[i].likelihood_metric(key))\n",
    "    jaccard_metric = jaccard_metric.at[1, i].set(GP_latent[i].jaccard_metric(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_metric for Marginal -0.11742856353521347\n",
      "number_metric for Latent 0.1348571628332138\n",
      "location_metric for Marginal 0.09127599000930786\n",
      "location_metric for Latent 0.140904039144516\n",
      "likelihood_metric for Marginal 242.09494018554688\n",
      "likelihood_metric for Latent 290.868896484375\n",
      "jaccard_metric for Marginal 0.954075813293457\n",
      "jaccard_metric for Latent 0.9459378123283386\n"
     ]
    }
   ],
   "source": [
    "print(f'number_metric for Marginal {jnp.mean(number_metric[0])}')\n",
    "print(f'number_metric for Latent {jnp.mean(number_metric[1])}')\n",
    "print(f'location_metric for Marginal {jnp.mean(location_metric[0])}')\n",
    "print(f'location_metric for Latent {jnp.mean(location_metric[1])}')\n",
    "print(f'likelihood_metric for Marginal {jnp.mean(likelihood_metric[0])}')\n",
    "print(f'likelihood_metric for Latent {jnp.mean(likelihood_metric[1])}')\n",
    "print(f'jaccard_metric for Marginal {jnp.mean(jaccard_metric[0])}')\n",
    "print(f'jaccard_metric for Latent {jnp.mean(jaccard_metric[1])}')\n",
    "# print(location_metric)\n",
    "# print(likelihood_metric)\n",
    "# print(jaccard_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading IHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Toy_dataset_RBF_3'\n",
    "num_runs = 3\n",
    "\n",
    "IHMM = []\n",
    "for i in range(num_runs):\n",
    "    IHMM.append(jnp.load(name + f'/IHMM/ihmm_trained_{i}.npy', allow_pickle = True)[()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric1_IHMM(ihmm, true_number):\n",
    "\n",
    "    def metric_func(max_states, z):\n",
    "        estimated_states = z.flatten()\n",
    "        uni_states = jnp.unique(estimated_states, size=max_states, fill_value=-1)\n",
    "        found_states = jnp.sum(uni_states>-1)-1\n",
    "        max_num = jnp.maximum(max_states - true_number, true_number)\n",
    "        return (found_states - true_number)/max_num\n",
    "    \n",
    "    if isinstance(ihmm, list):\n",
    "        result = []\n",
    "        num_back_steps = 500\n",
    "        for i, ihmm_ in enumerate(ihmm):\n",
    "            max_states = ihmm_.max_states\n",
    "            conv_z_arr = jnp.array(ihmm_.convergence['z'])\n",
    "            estimated_states = conv_z_arr[-num_back_steps:].squeeze()\n",
    "            result.append(jax.vmap(metric_func, in_axes=(None, 0))(max_states, estimated_states))\n",
    "        result = jnp.array(result)\n",
    "    else:\n",
    "        result = metric_func(ihmm.max_states, ihmm.z)\n",
    "    return jnp.mean(result)\n",
    "\n",
    "def metric2_IHMM(ihmm, true_locations):\n",
    "\n",
    "    if isinstance(ihmm, list):\n",
    "        size = len(ihmm[0].z[0, :])\n",
    "        x = np.linspace(0, 1, size)\n",
    "        CP_loc = []\n",
    "        num_back_steps = 500\n",
    "        max_num = ihmm[0].max_states\n",
    "        def find_CP(z):\n",
    "            size = z.shape[0]\n",
    "            size_arr = jnp.arange(size)\n",
    "            carry, CP_loc = jax.lax.scan(lambda carry, y: (y[0], jnp.where(carry != y[0], (y[1] + 1)/(size+1), jnp.nan)), z[0], jnp.concatenate((z[:, None], size_arr[:, None]), axis = 1))\n",
    "            return CP_loc\n",
    "        \n",
    "        for i, ihmm_ in enumerate(ihmm):\n",
    "            conv_z_arr = jnp.array(ihmm_.convergence['z'])\n",
    "            estimated_states = conv_z_arr[-num_back_steps:].squeeze()\n",
    "            # print(estimated_states.shape)\n",
    "            # for key, val in ihmm_.convergence.items():\n",
    "            #     ihmm_.convergence[key] = jnp.stack(val, axis = 0)\n",
    "            CP_loc.append(jax.vmap(find_CP, in_axes=(0, ))(estimated_states))\n",
    "        CP_IHMM = jnp.reshape(jnp.array(CP_loc[-num_back_steps:]), (len(ihmm) * num_back_steps, -1))\n",
    "        # print(CP_IHMM.shape)\n",
    "        loc_metric = jnp.zeros(len(ihmm) * num_back_steps)\n",
    "        for j, CP in enumerate(CP_IHMM):\n",
    "            CP_new = CP[~jnp.isnan(CP)]\n",
    "            found_states = len(CP_new)\n",
    "            dist = np.zeros((len(true_locations), found_states))\n",
    "            \n",
    "            max_dist = 1\n",
    "            for i, loc in enumerate(true_locations):\n",
    "                true_locs = np.sort(x[np.argsort(np.abs(x - loc))[:2]])\n",
    "                dist1 = (CP_new - true_locs[0])\n",
    "                dist2 = (CP_new - true_locs[1])\n",
    "                dist_comp = dist1 * dist2\n",
    "                dist_min = np.minimum(np.abs(dist1), np.abs(dist2))\n",
    "                dist_min[dist_comp < 0] = 0\n",
    "                dist[i, :] = np.abs(dist_min)\n",
    "            num_diff = np.abs(len(true_locations) - found_states)\n",
    "            sorted_min_dist = np.sort(np.min(dist, axis = 1))\n",
    "            if num_diff == 0:\n",
    "                loc_metric = loc_metric.at[j].set(np.sum(sorted_min_dist)/max_num)\n",
    "            else: \n",
    "                sorted_min_dist[-num_diff:] = max_dist\n",
    "                loc_metric = loc_metric.at[j].set(np.sum(sorted_min_dist)/max_num)\n",
    "        return jnp.mean(loc_metric)\n",
    "    else:\n",
    "        size = len(ihmm.z[0, :]) \n",
    "        x = np.linspace(0, 1, size)\n",
    "        estimated_states = ihmm.z[0, :]\n",
    "        CP_loc = np.where(estimated_states[:-1] != estimated_states[1:])[0] + 1\n",
    "        CP_IHMM = x[CP_loc]\n",
    "        found_states = len(CP_IHMM)\n",
    "        dist = np.zeros((len(true_locations), found_states))\n",
    "        max_num = ihmm.max_states\n",
    "        max_dist = 1\n",
    "        for i, loc in enumerate(true_locations):\n",
    "            true_locs = np.sort(x[np.argsort(np.abs(x - loc))[:2]])\n",
    "            dist1 = (CP_IHMM - true_locs[0])\n",
    "            dist2 = (CP_IHMM - true_locs[1])\n",
    "            dist_comp = dist1 * dist2\n",
    "            dist_min = np.minimum(np.abs(dist1), np.abs(dist2))\n",
    "            dist_min[dist_comp < 0] = 0\n",
    "            dist[i, :] = np.abs(dist_min)\n",
    "        num_diff = np.abs(len(true_locations) - found_states)\n",
    "        sorted_min_dist = np.sort(np.min(dist, axis = 1))\n",
    "        if num_diff == 0:\n",
    "            return np.sum(sorted_min_dist)/max_num\n",
    "        else: \n",
    "            sorted_min_dist[-num_diff:] = max_dist\n",
    "            return np.sum(sorted_min_dist)/max_num\n",
    "\n",
    "def metric3_IHMM(ihmm, y):\n",
    "\n",
    "    def MVN_gen(ihmm_sub):\n",
    "        mu = jax.vmap(lambda a, b: ihmm_sub['mu'].squeeze()[a] + ihmm_sub['A'].squeeze()[a] * b, in_axes=(1, 0))(ihmm_sub['z'], y[1:])\n",
    "        cov = jax.vmap(lambda a: 1/ihmm_sub['invSigma'].squeeze()[a], in_axes=(0, ))(ihmm_sub['z'])\n",
    "        MVN = dx.MultivariateNormalDiag(mu.squeeze(), cov.squeeze())\n",
    "        log_prob = MVN.log_prob(y[1:])\n",
    "        return log_prob\n",
    "\n",
    "    if isinstance(ihmm, list):\n",
    "        log_prob = []\n",
    "        for i, ihmm_ in enumerate(ihmm):\n",
    "            num_back_steps = 500\n",
    "            for key, val in ihmm_.convergence.items():\n",
    "                ihmm_.convergence[key] = jnp.stack(val, axis = 0)\n",
    "\n",
    "            ihmm_param_in_axes = jax.tree_map(lambda l: 0, ihmm_.convergence)\n",
    "            if ihmm_.convergence['nstates'].shape[0] != ihmm_.convergence['A'].shape[0]:\n",
    "                ihmm_.convergence['nstates'] = jnp.insert(ihmm_.convergence['nstates'], 0, ihmm_.convergence['nstates'][0])\n",
    "                ihmm_.convergence['z'] = jnp.append(ihmm_.convergence['z'][0][:, None], ihmm_.convergence['z'], axis = 0)\n",
    "            log_prob.append(jax.vmap(MVN_gen, in_axes = (ihmm_param_in_axes, ))(ihmm_.convergence))\n",
    "        log_prob = jnp.mean(jnp.array(log_prob))\n",
    "    else:\n",
    "        size = len(y)-1\n",
    "        mu = np.zeros(size)\n",
    "        cov = np.zeros(size)\n",
    "        for i, z in enumerate(ihmm.z.squeeze()):\n",
    "            # mu[i] = ihmm.theta['mu'].squeeze()[z]\n",
    "            mu[i] = ihmm.theta['mu'].squeeze()[z] + ihmm.theta['A'].squeeze()[z] * y[i]\n",
    "            cov[i] = 1/ihmm.theta['invSigma'].squeeze()[z]\n",
    "        MVN = dx.MultivariateNormalDiag(mu, cov)\n",
    "        log_prob = MVN.log_prob(y[1:])\n",
    "    return log_prob\n",
    "\n",
    "\n",
    "def metric4_IHMM(ihmm, true_locations):\n",
    "    if isinstance(ihmm, list):\n",
    "        size = len(ihmm[0].z[0, :])\n",
    "    else:\n",
    "        size = len(ihmm.z[0, :])\n",
    "    true_matrix = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "            for j in range(size):\n",
    "                if (np.sum(i < true_locations) == np.sum(j < true_locations)):\n",
    "                    true_matrix[i, j] = 1\n",
    "    \n",
    "    if isinstance(ihmm, list):\n",
    "        num_back_steps = 500\n",
    "        J_index = []\n",
    "\n",
    "        def gen_matrix(z):\n",
    "\n",
    "            def check_zero(x):\n",
    "                return jnp.where(x==0, jnp.nan, x)\n",
    "\n",
    "            def check_side(x_, y_):\n",
    "                return 1.0*(jnp.sum(jnp.less(x_, new_num)) == jnp.sum(jnp.less(y_, new_num)))\n",
    "\n",
    "            size = z.shape[0]\n",
    "            size_arr = jnp.arange(size)\n",
    "            carry, CP_loc = jax.lax.scan(lambda carry, y: (y[0], jnp.where(carry != y[0], (y[1] + 1), jnp.nan)), z[0], jnp.concatenate((z[:, None], size_arr[:, None]), axis = 1))\n",
    "            new_num = jax.vmap(lambda x: check_zero(x))(CP_loc)\n",
    "            cov_matrix = jax.vmap(lambda x_: jax.vmap(lambda y_: check_side(x_, y_))(size_arr))(size_arr)\n",
    "            return jnp.sum(1 - jnp.abs(cov_matrix - true_matrix))/(size**2)\n",
    "\n",
    "        for i, ihmm_ in enumerate(ihmm):\n",
    "            conv_z_arr = jnp.array(ihmm_.convergence['z'])\n",
    "            estimated_states = conv_z_arr[-num_back_steps:].squeeze()\n",
    "            J_index.append(jax.vmap(gen_matrix, in_axes=(0, ))(estimated_states))\n",
    "        J_index = jnp.mean(jnp.array(J_index))\n",
    "    \n",
    "    else:\n",
    "        estimated_states = ihmm.z[0, :]\n",
    "        CP_loc = np.where(estimated_states[:-1] != estimated_states[1:])[0] + 2 \n",
    "        cov_matrix = np.zeros((size,size))\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                if (np.sum(i < CP_loc) == np.sum(j < CP_loc)):\n",
    "                    cov_matrix[i, j] = 1\n",
    "        J_index = np.sum(1 - np.abs(cov_matrix - true_matrix))/(size**2)\n",
    "\n",
    "    return J_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02838298\n",
      "0.038140878\n",
      "-122.69601\n",
      "0.9557052\n"
     ]
    }
   ],
   "source": [
    "y = jnp.load(name + '/orig_data.npy')\n",
    "ground_truth = jnp.load(name + f'/ground_truth.npy', allow_pickle = True)[()]\n",
    "true_number = len(ground_truth['kernel']['num'])\n",
    "true_locations = jnp.sort(ground_truth['kernel']['num']) * len(y)\n",
    "# print(true_locations)\n",
    "\n",
    "number_metric_IHMM = metric1_IHMM(IHMM, true_number)\n",
    "print(number_metric_IHMM)\n",
    "location_metric_IHMM = metric2_IHMM(IHMM, true_locations)\n",
    "print(location_metric_IHMM)\n",
    "likelihood_metric_IHMM = metric3_IHMM(IHMM, y)\n",
    "print(likelihood_metric_IHMM)\n",
    "jaccard_metric_IHMM = metric4_IHMM(IHMM, true_locations)\n",
    "print(jaccard_metric_IHMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 30. 70.]\n"
     ]
    }
   ],
   "source": [
    "# key = jrnd.PRNGKey(1234)\n",
    "number_metric_IHMM = jnp.zeros((3))\n",
    "location_metric_IHMM = jnp.zeros((3))\n",
    "likelihood_metric_IHMM = jnp.zeros((3))\n",
    "jaccard_metric_IHMM = jnp.zeros((3))\n",
    "\n",
    "y = jnp.load(name + '/orig_data.npy')\n",
    "ground_truth = jnp.load(name + f'/ground_truth.npy', allow_pickle = True)[()]\n",
    "true_number = len(ground_truth['kernel']['num'])\n",
    "true_locations = jnp.sort(ground_truth['kernel']['num']) * len(y)\n",
    "print(true_locations)\n",
    "\n",
    "for i in range(num_runs):\n",
    "    number_metric_IHMM = number_metric_IHMM.at[i].set(metric1_IHMM(IHMM[i], true_number))\n",
    "    location_metric_IHMM = location_metric_IHMM.at[i].set(metric2_IHMM(IHMM[i], true_locations))\n",
    "    likelihood_metric_IHMM = likelihood_metric_IHMM.at[i].set(metric3_IHMM(IHMM[i], y))\n",
    "    jaccard_metric_IHMM = jaccard_metric_IHMM.at[i].set(metric4_IHMM(IHMM[i],true_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_metric for IHMM 0.021276595070958138\n",
      "location_metric for IHMM 0.03142857179045677\n",
      "likelihood_metric for IHMM -145.8402099609375\n",
      "jaccard_metric for IHMM 0.9618406295776367\n"
     ]
    }
   ],
   "source": [
    "print(f'number_metric for IHMM {jnp.mean(number_metric_IHMM[0])}')\n",
    "print(f'location_metric for IHMM {jnp.mean(location_metric_IHMM[0])}')\n",
    "print(f'likelihood_metric for IHMM {jnp.mean(likelihood_metric_IHMM[0])}')\n",
    "print(f'jaccard_metric for IHMM {jnp.mean(jaccard_metric_IHMM[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPJax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
